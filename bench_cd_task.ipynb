{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "config = Namespace(\n",
    "    data_folder='./wm_bench_data', \n",
    "    max_seq_len=20, \n",
    "    rs_img_size=32, \n",
    "    batch_size=10, \n",
    "    num_workers=4, \n",
    "    use_cnn=1, \n",
    "    model_path='./trained_models/LSTM/256/model.pt'\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data_utils import get_test_multitask_dataloader\n",
    "\n",
    "test_loader = get_test_multitask_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import WM_Model\n",
    "\n",
    "model_data = torch.load(config.model_path)\n",
    "model = WM_Model(Namespace(**model_data['config']), device).to(device)\n",
    "model.load_state_dict(model_data['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model_1': model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epoch_acc = {}\n",
    "\n",
    "dataloader = zip(*test_loader.values())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, multitask_batch in tqdm(enumerate(dataloader)):\n",
    "        stim_batch, resp_batch, seq_len, ri, set_size = multitask_batch[8]\n",
    "\n",
    "        stim_batch = stim_batch.to(device)\n",
    "        resp_batch = resp_batch.to(device)\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            out, _, _, _, _ = model(stim_batch, 'CD_Color_Task', seq_len)\n",
    "            pred = torch.round(torch.sigmoid(out))\n",
    "\n",
    "            for index, length in enumerate(seq_len):\n",
    "                if model_name+'_Color_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item()) not in epoch_acc:\n",
    "                    epoch_acc[model_name+'_Color_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())] = []\n",
    "\n",
    "                if (pred[index, length-1] == resp_batch[index, length-1]).item():\n",
    "                    epoch_acc[model_name+'_Color_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(1)\n",
    "                else:\n",
    "                    epoch_acc[model_name+'_Color_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(0)\n",
    "\n",
    "        \n",
    "\n",
    "        stim_batch, resp_batch, seq_len, ri, set_size = multitask_batch[9]\n",
    "\n",
    "        stim_batch = stim_batch.to(device)\n",
    "        resp_batch = resp_batch.to(device)\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            out, _, _, _, _ = model(stim_batch, 'CD_Orientation_Task', seq_len)\n",
    "            pred = torch.round(torch.sigmoid(out))\n",
    "\n",
    "            for index, length in enumerate(seq_len):\n",
    "                if model_name+'_Orientation_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item()) not in epoch_acc:\n",
    "                    epoch_acc[model_name+'_Orientation_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())] = []\n",
    "\n",
    "                if (pred[index, length-1] == resp_batch[index, length-1]).item():\n",
    "                    epoch_acc[model_name+'_Orientation_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(1)\n",
    "                else:\n",
    "                    epoch_acc[model_name+'_Orientation_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(0)\n",
    "\n",
    "\n",
    "\n",
    "        stim_batch, resp_batch, seq_len, ri, set_size = multitask_batch[10]\n",
    "\n",
    "        stim_batch = stim_batch.to(device)\n",
    "        resp_batch = resp_batch.to(device)\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            out, _, _, _, _ = model(stim_batch, 'CD_Size_Task', seq_len)\n",
    "            pred = torch.round(torch.sigmoid(out))\n",
    "\n",
    "            for index, length in enumerate(seq_len):\n",
    "                if model_name+'_Size_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item()) not in epoch_acc:\n",
    "                    epoch_acc[model_name+'_Size_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())] = []\n",
    "\n",
    "                if (pred[index, length-1] == resp_batch[index, length-1]).item():\n",
    "                    epoch_acc[model_name+'_Size_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(1)\n",
    "                else:\n",
    "                    epoch_acc[model_name+'_Size_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(0)\n",
    "\n",
    "\n",
    "\n",
    "        stim_batch, resp_batch, seq_len, ri, set_size = multitask_batch[11]\n",
    "\n",
    "        stim_batch = stim_batch.to(device)\n",
    "        resp_batch = resp_batch.to(device)\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            out, _, _, _, _ = model(stim_batch, 'CD_Gap_Task', seq_len)\n",
    "            pred = torch.round(torch.sigmoid(out))\n",
    "\n",
    "            for index, length in enumerate(seq_len):\n",
    "                if model_name+'_Gap_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item()) not in epoch_acc:\n",
    "                    epoch_acc[model_name+'_Gap_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())] = []\n",
    "\n",
    "                if (pred[index, length-1] == resp_batch[index, length-1]).item():\n",
    "                    epoch_acc[model_name+'_Gap_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(1)\n",
    "                else:\n",
    "                    epoch_acc[model_name+'_Gap_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(0)\n",
    "\n",
    "\n",
    "        \n",
    "        stim_batch, resp_batch, seq_len, ri, set_size, conj_gt = multitask_batch[12]\n",
    "\n",
    "        stim_batch = stim_batch.to(device)\n",
    "        resp_batch = resp_batch.to(device)\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            out, _, _, _, _ = model(stim_batch, 'CD_Conj_Task', seq_len)\n",
    "            pred = torch.round(torch.sigmoid(out))\n",
    "\n",
    "            for index, length in enumerate(seq_len):\n",
    "                if model_name+'_Conj_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item()) not in epoch_acc:\n",
    "                    epoch_acc[model_name+'_Conj_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())] = []\n",
    "\n",
    "                if (pred[index, length-1] == resp_batch[index, length-1]).item():\n",
    "                    epoch_acc[model_name+'_Conj_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(1)\n",
    "                else:\n",
    "                    epoch_acc[model_name+'_Conj_Set_Size_'+str(set_size[index].item())+'_RI_'+str(ri[index].item())].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cd_accs.json', 'w') as fp:\n",
    "    json.dump(epoch_acc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "epoch_acc_std_err = {}\n",
    "\n",
    "for key in epoch_acc:\n",
    "    epoch_acc_std_err[key] = [np.mean(epoch_acc[key]), \n",
    "                              np.std(epoch_acc[key])/np.sqrt(len(epoch_acc[key]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "\n",
    "for key in list(epoch_acc_std_err.keys()):\n",
    "    model = key.split('_')[0] + '_' + key.split('_')[1]\n",
    "    feature = key.split('_')[2]\n",
    "    set_size = key.split('_')[5]\n",
    "    ri = key.split('_')[7]\n",
    "\n",
    "    if model not in plot_data:\n",
    "        plot_data[model] = {}\n",
    "\n",
    "    if feature not in plot_data[model]:\n",
    "        plot_data[model][feature] = {}\n",
    "\n",
    "    if ri not in plot_data[model][feature]:\n",
    "        plot_data[model][feature][ri] = [[], [], []]\n",
    "\n",
    "    plot_data[model][feature][ri][0].append(int(set_size))\n",
    "    plot_data[model][feature][ri][1].append(epoch_acc_std_err[key][0])\n",
    "    plot_data[model][feature][ri][2].append(epoch_acc_std_err[key][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_plot_data = {\n",
    "    'Color': [[2, 4, 6], [0.985, 0.945, 0.84]], \n",
    "    'Orientation': [[2, 4, 6], [0.955, 0.90, 0.81]], \n",
    "    'Size': [[2, 4, 6], [0.975, 0.93, 0.82]], \n",
    "    'Gap': [[2, 4, 6], [0.945, 0.89, 0.80]], \n",
    "    'Conjunction': [[2, 4, 6], [0.965, 0.92, 0.83]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Serif\"\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for model in plot_data:\n",
    "    if model == 'rnn_96':\n",
    "        for feature in plot_data[model]:\n",
    "            for ri in plot_data[model][feature]:\n",
    "                if ri in ['18']:\n",
    "                    if feature == 'Conj':\n",
    "                        ax.errorbar(plot_data[model][feature][ri][0], \n",
    "                                    plot_data[model][feature][ri][1], \n",
    "                                    yerr=0, \n",
    "                                    label='RNN-96'+' '+'Conjunction', \n",
    "                                    linewidth=1.5, markersize=6, fmt='-s')\n",
    "                    else:\n",
    "                        ax.errorbar(plot_data[model][feature][ri][0], \n",
    "                                    plot_data[model][feature][ri][1], \n",
    "                                    yerr=0, \n",
    "                                    label='RNN-96'+' '+feature, \n",
    "                                    linewidth=1.5, markersize=6, fmt='-s')\n",
    "                        \n",
    "\n",
    "for feature in human_plot_data:\n",
    "    if feature == 'Conj':\n",
    "        ax.errorbar(human_plot_data[feature][0], \n",
    "                    human_plot_data[feature][1], \n",
    "                    yerr=0, \n",
    "                    label='Human'+' '+'Conjunction', \n",
    "                    linewidth=1.5, markersize=6, fmt='--o')\n",
    "    else:\n",
    "        ax.errorbar(human_plot_data[feature][0], \n",
    "                    human_plot_data[feature][1], \n",
    "                    yerr=0, \n",
    "                    label='Human'+' '+feature, \n",
    "                    linewidth=1.5, markersize=6, fmt='--o')\n",
    "\n",
    "                \n",
    "sns.despine(left=False, bottom=False, right=True, top=True)\n",
    "\n",
    "ax.set_xlabel('Set Size', fontsize=20)\n",
    "ax.set_ylabel('Top-1 Accuracy', fontsize=20)\n",
    "\n",
    "ax.set_yticks([0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "ax.set_ylim([0.7, 1.01])\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.legend(frameon=False, loc='upper center', bbox_to_anchor=(1.15, 0.87), ncol=1, prop={'size': 14})\n",
    "\n",
    "plt.savefig('cd_accs_fin.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
