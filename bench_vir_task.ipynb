{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "config = Namespace(\n",
    "    data_folder='./wm_bench_data', \n",
    "    max_seq_len=20, \n",
    "    rs_img_size=32, \n",
    "    batch_size=10, \n",
    "    num_workers=4, \n",
    "    use_cnn=1, \n",
    "    model_path='./model.pt'\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data_utils import get_test_multitask_dataloader\n",
    "\n",
    "test_loader = get_test_multitask_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import WM_Model\n",
    "\n",
    "model_data = torch.load(config.model_path)\n",
    "model = WM_Model(Namespace(**model_data['config']), device).to(device)\n",
    "model.load_state_dict(model_data['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model_1': model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epoch_acc = {}\n",
    "\n",
    "dataloader = zip(*test_loader.values())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, multitask_batch in tqdm(enumerate(dataloader)):\n",
    "        stim_batch, resp_batch, seq_len, ri, gt_index = multitask_batch[5]\n",
    "\n",
    "        stim_batch = stim_batch.to(device)\n",
    "        resp_batch = resp_batch.to(device)\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            out, _, _, _, _ = model(stim_batch, 'VIRec_2C_Task', seq_len)\n",
    "            pred = torch.round(torch.sigmoid(out))\n",
    "\n",
    "            for index, length in enumerate(seq_len):\n",
    "                ll = length.item() - ri[index].item() - 1\n",
    "                if (model_name+'_RI_'+str(ri[index].item())+'_LL_'+str(ll)+'_SP_'+\n",
    "                    str(gt_index[index].item())) not in epoch_acc:\n",
    "                    epoch_acc[model_name+'_RI_'+str(ri[index].item())+'_LL_'+str(ll)+'_SP_'+str(gt_index[index].item())] = []\n",
    "\n",
    "                if pred[index, length-1] == resp_batch[index, length-1]:\n",
    "                    epoch_acc[model_name+'_RI_'+str(ri[index].item())+'_LL_'+str(ll)+'_SP_'+str(gt_index[index].item())].append(1)\n",
    "                else:\n",
    "                    epoch_acc[model_name+'_RI_'+str(ri[index].item())+'_LL_'+str(ll)+'_SP_'+str(gt_index[index].item())].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('vir_accs.json', 'w') as fp:\n",
    "    json.dump(epoch_acc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "epoch_acc_std_err = {}\n",
    "\n",
    "for key in epoch_acc:\n",
    "    epoch_acc_std_err[key] = [np.mean(epoch_acc[key]), \n",
    "                              stats.sem(epoch_acc[key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "\n",
    "for key in list(epoch_acc_std_err.keys()):\n",
    "    model = key.split('_')[0] + '_' + key.split('_')[1] + '_' + key.split('_')[2]\n",
    "    ri = key.split('_')[4]\n",
    "    ll = key.split('_')[6]\n",
    "    sp = int(key.split('_')[8]) + 1\n",
    "\n",
    "    if model not in plot_data:\n",
    "        plot_data[model] = {}\n",
    "\n",
    "    if ll not in plot_data[model]:\n",
    "        plot_data[model][ll] = {}\n",
    "\n",
    "    if ri not in plot_data[model][ll]:\n",
    "        plot_data[model][ll][ri] = [[], [], []]\n",
    "\n",
    "    plot_data[model][ll][ri][0].append(sp)\n",
    "    plot_data[model][ll][ri][1].append(epoch_acc_std_err[key][0])\n",
    "    plot_data[model][ll][ri][2].append(epoch_acc_std_err[key][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_plot_data = {}\n",
    "\n",
    "for model in plot_data:\n",
    "    for ll in plot_data[model]:\n",
    "        for ri in plot_data[model][ll]:\n",
    "            sp = plot_data[model][ll][ri][0]\n",
    "            acc = plot_data[model][ll][ri][1]\n",
    "            err = plot_data[model][ll][ri][2]\n",
    "\n",
    "            sp, acc, err = zip(*sorted(zip(sp, acc, err)))\n",
    "\n",
    "            if model not in sorted_plot_data:\n",
    "                sorted_plot_data[model] = {}\n",
    "\n",
    "            if ll not in sorted_plot_data[model]:\n",
    "                sorted_plot_data[model][ll] = {}\n",
    "\n",
    "            if ri not in sorted_plot_data[model][ll]:\n",
    "                sorted_plot_data[model][ll][ri] = [[], [], []]\n",
    "\n",
    "            sorted_plot_data[model][ll][ri][0] = sp\n",
    "            sorted_plot_data[model][ll][ri][1] = acc\n",
    "            sorted_plot_data[model][ll][ri][2] = err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Serif\"\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for model in sorted_plot_data:\n",
    "    if model == 'trf_96_1':\n",
    "        for ll in sorted_plot_data[model]:\n",
    "            if ll in ['4']:\n",
    "                for ri in sorted_plot_data[model][ll]:\n",
    "                    if ri in ['0', '5']:\n",
    "                        sp = sorted_plot_data[model][ll][ri][0]\n",
    "                        acc = sorted_plot_data[model][ll][ri][1]\n",
    "                        err = sorted_plot_data[model][ll][ri][2]\n",
    "\n",
    "                        ax.errorbar(sp, acc, yerr=err, label='TRF-256 RI = '+ri, linewidth=2, \n",
    "                                marker='s', markersize=3, capsize=4)\n",
    "\n",
    "ax.plot([1, 2, 3, 4], [0.655, 0.66, 0.645, 0.81], linestyle='--', color='C0', \n",
    "        linewidth=2, marker='s', markersize=7, label='Human RI = 0')\n",
    "ax.plot([1, 2, 3, 4], [0.655, 0.705, 0.68, 0.71], linestyle='--', color='C1', \n",
    "        linewidth=2, marker='s', markersize=7, label='Human RI = 5')\n",
    "\n",
    "sns.despine(left=False, bottom=False, right=True, top=True)\n",
    "\n",
    "ax.set_xlabel('Serial Position', fontsize=25)\n",
    "ax.set_ylabel('Top-1 Accuracy', fontsize=25)\n",
    "\n",
    "ax.set_xticks([1, 2, 3, 4])\n",
    "ax.set_xticklabels([1, 2, 3, 4])\n",
    "\n",
    "ax.set_ylim([0.5, 1.01])\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.legend(frameon=False, loc='upper center', ncol=1, bbox_to_anchor=(1.39, 1.0), \n",
    "           prop={'size': 16})\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
